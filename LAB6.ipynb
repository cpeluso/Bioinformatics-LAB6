{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArwqPRT6ELto"
      },
      "source": [
        "### Assignment 1: Implement a Bayesian Convolutional Neural Network\n",
        "\n",
        "The Bayesian Convolutional Neural Network should distinguish between oncogenic and not oncogenic gene fusions exploiting the gene fusion sequence.\n",
        "\n",
        "In details, analyze and explore the certainty classification value for the samples which are correctly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "DUhmspHnFZda",
        "outputId": "10ab36dd-31b9-47be-8452-69ac40ca8f1e"
      },
      "source": [
        "to_drop_columns = ['Unnamed: 0', 'MainProteins', '5pEnsg', '3pEnsg', 'Version', '5pGeneFunctionality', '3pGeneFunctionality', '5pGeneDescription', '3pGeneDescription', '5pCommonName', '3pCommonName']\n",
        "\n",
        "train_df = pd.read_table(TRAINING_SET).drop(to_drop_columns, 1)\n",
        "test_df  = pd.read_table(TEST_SET)    .drop(to_drop_columns, 1)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FusionPair</th>\n",
              "      <th>Label</th>\n",
              "      <th>Chr5p</th>\n",
              "      <th>Coord5p</th>\n",
              "      <th>5pStrand</th>\n",
              "      <th>Chr3p</th>\n",
              "      <th>Coord3p</th>\n",
              "      <th>3pStrand</th>\n",
              "      <th>Proteins</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCDC6_RET</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>61665880</td>\n",
              "      <td>-</td>\n",
              "      <td>10</td>\n",
              "      <td>43612032</td>\n",
              "      <td>+</td>\n",
              "      <td>['MADSASESDTDGAGGNSSSSAAMQSSCSSTSGGGGGGGGGGGGG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TMPRSS2_ERG</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>42870046</td>\n",
              "      <td>-</td>\n",
              "      <td>21</td>\n",
              "      <td>39795483</td>\n",
              "      <td>-</td>\n",
              "      <td>['MALNSELS']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TMPRSS2_ERG</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>42880008</td>\n",
              "      <td>-</td>\n",
              "      <td>21</td>\n",
              "      <td>39817544</td>\n",
              "      <td>-</td>\n",
              "      <td>['EALSVVSEDQSLFECAYGTPHLAKTEMTASSSSDYGQTSKMSPR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TMPRSS2_ERG</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>42880008</td>\n",
              "      <td>-</td>\n",
              "      <td>21</td>\n",
              "      <td>39956869</td>\n",
              "      <td>-</td>\n",
              "      <td>['MIQTVPDPAAHIKEALSVVSEDQSLFECAYGTPHLAKTEMTASS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TMPRSS2_ERG</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>42870046</td>\n",
              "      <td>-</td>\n",
              "      <td>21</td>\n",
              "      <td>39956869</td>\n",
              "      <td>-</td>\n",
              "      <td>['MALNSMIQTVPDPAAHIKEALSVVSEDQSLFECAYGTPHLAKTE...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FusionPair  ...                                           Proteins\n",
              "0    CCDC6_RET  ...  ['MADSASESDTDGAGGNSSSSAAMQSSCSSTSGGGGGGGGGGGGG...\n",
              "1  TMPRSS2_ERG  ...                                       ['MALNSELS']\n",
              "2  TMPRSS2_ERG  ...  ['EALSVVSEDQSLFECAYGTPHLAKTEMTASSSSDYGQTSKMSPR...\n",
              "3  TMPRSS2_ERG  ...  ['MIQTVPDPAAHIKEALSVVSEDQSLFECAYGTPHLAKTEMTASS...\n",
              "4  TMPRSS2_ERG  ...  ['MALNSMIQTVPDPAAHIKEALSVVSEDQSLFECAYGTPHLAKTE...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-Fi8NS_SSyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c9bf13-5c0d-436e-fdce-45c9deebfee5"
      },
      "source": [
        "train_df.Proteins = train_df.Proteins.apply(lambda protein: protein.replace(\"\\'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\"))\n",
        "test_df .Proteins = test_df .Proteins.apply(lambda protein: protein.replace(\"\\'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\"))\n",
        "\n",
        "train_df = clean_dataset(train_df)\n",
        "test_df  = clean_dataset(test_df)\n",
        "print(\"Cleaned protein sequences\")\n",
        "\n",
        "aminoacids_map = compute_one_hot_encoding_map(train_df)\n",
        "print(\"Computed one hot encoding map\")\n",
        "\n",
        "train_df.Proteins = train_df.Proteins.apply(lambda protein: one_hot_encode(aminoacids_map, protein))\n",
        "test_df .Proteins = test_df .Proteins.apply(lambda protein: one_hot_encode(aminoacids_map, protein))\n",
        "print(\"Encoded proteins!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaned protein sequences\n",
            "Computed one hot encoding map\n",
            "Encoded proteins!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1Wc9DuwOIfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1196924b-6c03-4b59-b5ea-d9042846dfc4"
      },
      "source": [
        "X_train = np.stack(train_df.Proteins)\n",
        "X_test  = np.stack(test_df .Proteins)\n",
        "\n",
        "combined = pd.concat([train_df.copy(), test_df.copy()])\n",
        "labels   = utils.to_categorical(combined.Label)\n",
        "\n",
        "y_train  = labels[:len(train_df)]\n",
        "y_test   = labels[len(train_df):]\n",
        "\n",
        "print(\"Features train dataset shape:\\t\" + str(X_train.shape))\n",
        "print(\"Labels train dataset shape:\\t\"   + str(y_train.shape))\n",
        "\n",
        "print(\"Features test dataset shape:\\t\"  + str(X_test.shape))\n",
        "print(\"Labels test dataset shape:\\t\"    + str(y_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features train dataset shape:\t(2118, 5000, 22)\n",
            "Labels train dataset shape:\t(2118, 2)\n",
            "Features test dataset shape:\t(896, 5000, 22)\n",
            "Labels test dataset shape:\t(896, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBK0ACBHfaRZ"
      },
      "source": [
        "#### Basic CNN 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyxnRphVXUan",
        "outputId": "e2e44425-b133-4865-94f4-3bdcff6da503"
      },
      "source": [
        "EPOCHS      = 75\n",
        "BATCH_SIZE  = 128\n",
        "LR          = 0.001\n",
        "INPUT_SHAPE = X_train[0].shape\n",
        "NUM_CLASSES = len(np.unique(y_train))\n",
        "\n",
        "cnn = CNN(\n",
        "    EPOCHS,\n",
        "    BATCH_SIZE,\n",
        "    LR,\n",
        "    INPUT_SHAPE,\n",
        "    NUM_CLASSES,\n",
        "    \"Basic\"\n",
        ")\n",
        "\n",
        "cnn.train_model(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Basic model.\n",
            "Epoch 1/75\n",
            "15/15 [==============================] - 2s 117ms/step - loss: 2.7707 - accuracy: 0.6156 - val_loss: 0.6145 - val_accuracy: 0.6967\n",
            "Epoch 2/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.5054 - accuracy: 0.7819 - val_loss: 0.4334 - val_accuracy: 0.8294\n",
            "Epoch 3/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.3872 - accuracy: 0.8464 - val_loss: 0.3253 - val_accuracy: 0.8863\n",
            "Epoch 4/75\n",
            "15/15 [==============================] - 1s 89ms/step - loss: 0.2992 - accuracy: 0.8862 - val_loss: 0.2636 - val_accuracy: 0.8957\n",
            "Epoch 5/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.2277 - accuracy: 0.9046 - val_loss: 0.2166 - val_accuracy: 0.9336\n",
            "Epoch 6/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.1736 - accuracy: 0.9350 - val_loss: 0.1983 - val_accuracy: 0.9289\n",
            "Epoch 7/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.1363 - accuracy: 0.9544 - val_loss: 0.1887 - val_accuracy: 0.9289\n",
            "Epoch 8/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.1153 - accuracy: 0.9554 - val_loss: 0.1705 - val_accuracy: 0.9242\n",
            "Epoch 9/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0884 - accuracy: 0.9685 - val_loss: 0.1900 - val_accuracy: 0.9289\n",
            "Epoch 10/75\n",
            "15/15 [==============================] - 1s 94ms/step - loss: 0.0759 - accuracy: 0.9717 - val_loss: 0.1875 - val_accuracy: 0.9147\n",
            "Epoch 11/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0654 - accuracy: 0.9769 - val_loss: 0.1806 - val_accuracy: 0.9289\n",
            "Epoch 12/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0569 - accuracy: 0.9775 - val_loss: 0.2047 - val_accuracy: 0.9242\n",
            "Epoch 13/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.1904 - val_accuracy: 0.9147\n",
            "Epoch 14/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0408 - accuracy: 0.9837 - val_loss: 0.1997 - val_accuracy: 0.9289\n",
            "Epoch 15/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0382 - accuracy: 0.9869 - val_loss: 0.2455 - val_accuracy: 0.9289\n",
            "Epoch 16/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.1944 - val_accuracy: 0.9289\n",
            "Epoch 17/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0302 - accuracy: 0.9874 - val_loss: 0.2337 - val_accuracy: 0.9384\n",
            "Epoch 18/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0302 - accuracy: 0.9874 - val_loss: 0.2296 - val_accuracy: 0.9289\n",
            "Epoch 19/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.1964 - val_accuracy: 0.9289\n",
            "Epoch 20/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0233 - accuracy: 0.9911 - val_loss: 0.2414 - val_accuracy: 0.9384\n",
            "Epoch 21/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.2406 - val_accuracy: 0.9336\n",
            "Epoch 22/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.2184 - val_accuracy: 0.9336\n",
            "Epoch 23/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.2627 - val_accuracy: 0.9336\n",
            "Epoch 24/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.2795 - val_accuracy: 0.9289\n",
            "Epoch 25/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.2764 - val_accuracy: 0.9289\n",
            "Epoch 26/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.2796 - val_accuracy: 0.9336\n",
            "Epoch 27/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9336\n",
            "Epoch 28/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9336\n",
            "Epoch 29/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.2788 - val_accuracy: 0.9336\n",
            "Epoch 30/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.2828 - val_accuracy: 0.9384\n",
            "Epoch 31/75\n",
            "15/15 [==============================] - 1s 94ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.2864 - val_accuracy: 0.9336\n",
            "Epoch 32/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.3109 - val_accuracy: 0.9336\n",
            "Epoch 33/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.2912 - val_accuracy: 0.9384\n",
            "Epoch 34/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.3087 - val_accuracy: 0.9384\n",
            "Epoch 35/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0228 - accuracy: 0.9963 - val_loss: 0.3459 - val_accuracy: 0.9242\n",
            "Epoch 36/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 0.3018 - val_accuracy: 0.9194\n",
            "Epoch 37/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0248 - accuracy: 0.9963 - val_loss: 0.2337 - val_accuracy: 0.9289\n",
            "Epoch 38/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0150 - accuracy: 0.9995 - val_loss: 0.2433 - val_accuracy: 0.9242\n",
            "Epoch 39/75\n",
            "15/15 [==============================] - 1s 89ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.2639 - val_accuracy: 0.9431\n",
            "Epoch 40/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9431\n",
            "Epoch 41/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9384\n",
            "Epoch 42/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9384\n",
            "Epoch 43/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9336\n",
            "Epoch 44/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.3154 - val_accuracy: 0.9384\n",
            "Epoch 45/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9384\n",
            "Epoch 46/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3339 - val_accuracy: 0.9336\n",
            "Epoch 47/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9431\n",
            "Epoch 48/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3464 - val_accuracy: 0.9431\n",
            "Epoch 49/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9384\n",
            "Epoch 50/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9384\n",
            "Epoch 51/75\n",
            "15/15 [==============================] - 1s 94ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9384\n",
            "Epoch 52/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9336\n",
            "Epoch 53/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9384\n",
            "Epoch 54/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3713 - val_accuracy: 0.9431\n",
            "Epoch 55/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9431\n",
            "Epoch 56/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3744 - val_accuracy: 0.9384\n",
            "Epoch 57/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 8.5899e-04 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9431\n",
            "Epoch 58/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9336\n",
            "Epoch 59/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9336\n",
            "Epoch 60/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3899 - val_accuracy: 0.9431\n",
            "Epoch 61/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 8.2886e-04 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9431\n",
            "Epoch 62/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 8.9649e-04 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9431\n",
            "Epoch 63/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9431\n",
            "Epoch 64/75\n",
            "15/15 [==============================] - 1s 89ms/step - loss: 8.1446e-04 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9431\n",
            "Epoch 65/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9431\n",
            "Epoch 66/75\n",
            "15/15 [==============================] - 1s 92ms/step - loss: 7.0243e-04 - accuracy: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.9431\n",
            "Epoch 67/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.3861 - val_accuracy: 0.9384\n",
            "Epoch 68/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 4.9762e-04 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9384\n",
            "Epoch 69/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 8.8300e-04 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9336\n",
            "Epoch 70/75\n",
            "15/15 [==============================] - 1s 88ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9336\n",
            "Epoch 71/75\n",
            "15/15 [==============================] - 1s 89ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9336\n",
            "Epoch 72/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 7.4328e-04 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9336\n",
            "Epoch 73/75\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 7.7125e-04 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.9336\n",
            "Epoch 74/75\n",
            "15/15 [==============================] - 1s 91ms/step - loss: 8.9542e-04 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9336\n",
            "Epoch 75/75\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 8.0631e-04 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.9336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-HVWjR7YEjS",
        "outputId": "a4972d44-fd81-44c0-90d9-e6a3c3fa524b"
      },
      "source": [
        "loss, acc   = cnn.model.evaluate(X_test, y_test, verbose=False);\n",
        "predictions = cnn.model.predict(X_test)\n",
        "print(\"Test done!\")\n",
        "print(\"Mean accuracy:\\t {}\\nLoss:\\t\\t {}\".format(acc, loss))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test done!\n",
            "Mean accuracy:\t 0.2276785671710968\n",
            "Loss:\t\t 4.505393981933594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oACoSXu5fftG"
      },
      "source": [
        "#### Bayesian CNN 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBVo8gjpHtI2",
        "outputId": "bde4fecd-5f00-41b9-82e2-3d6c239d8182"
      },
      "source": [
        "EPOCHS      = 75\n",
        "BATCH_SIZE  = 32\n",
        "LR          = 0.0001\n",
        "INPUT_SHAPE = X_train[0].shape\n",
        "NUM_CLASSES = len(np.unique(y_train))\n",
        "MODEL       = \"Bayesian\"\n",
        "\n",
        "bcnn = CNN(\n",
        "    EPOCHS,\n",
        "    BATCH_SIZE,\n",
        "    LR,\n",
        "    INPUT_SHAPE,\n",
        "    NUM_CLASSES, \n",
        "    MODEL\n",
        ")\n",
        "\n",
        "bcnn.train_model(X_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Bayesian model.\n",
            "Epoch 1/75\n",
            " 2/60 [>.............................] - ETA: 7s - loss: 5.0973 - accuracy: 0.5469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0911s vs `on_train_batch_end` time: 0.1741s). Check your callbacks.\n",
            "60/60 [==============================] - 17s 280ms/step - loss: 1.9452 - accuracy: 0.5034 - val_loss: 0.8040 - val_accuracy: 0.4645\n",
            "Epoch 2/75\n",
            "60/60 [==============================] - 16s 274ms/step - loss: 0.7192 - accuracy: 0.5113 - val_loss: 0.7045 - val_accuracy: 0.4787\n",
            "Epoch 3/75\n",
            "60/60 [==============================] - 17s 278ms/step - loss: 0.6984 - accuracy: 0.5322 - val_loss: 0.7009 - val_accuracy: 0.5213\n",
            "Epoch 4/75\n",
            "60/60 [==============================] - 17s 285ms/step - loss: 0.6904 - accuracy: 0.5469 - val_loss: 0.6847 - val_accuracy: 0.5592\n",
            "Epoch 5/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.6756 - accuracy: 0.5878 - val_loss: 0.6762 - val_accuracy: 0.5687\n",
            "Epoch 6/75\n",
            "60/60 [==============================] - 18s 302ms/step - loss: 0.6615 - accuracy: 0.6041 - val_loss: 0.6300 - val_accuracy: 0.6777\n",
            "Epoch 7/75\n",
            "60/60 [==============================] - 18s 306ms/step - loss: 0.6265 - accuracy: 0.6586 - val_loss: 0.5795 - val_accuracy: 0.7062\n",
            "Epoch 8/75\n",
            "60/60 [==============================] - 18s 298ms/step - loss: 0.6106 - accuracy: 0.6765 - val_loss: 0.5872 - val_accuracy: 0.6777\n",
            "Epoch 9/75\n",
            "60/60 [==============================] - 18s 297ms/step - loss: 0.6080 - accuracy: 0.6801 - val_loss: 0.5710 - val_accuracy: 0.7109\n",
            "Epoch 10/75\n",
            "60/60 [==============================] - 18s 296ms/step - loss: 0.5874 - accuracy: 0.6964 - val_loss: 0.5906 - val_accuracy: 0.6919\n",
            "Epoch 11/75\n",
            "60/60 [==============================] - 18s 300ms/step - loss: 0.5872 - accuracy: 0.6917 - val_loss: 0.5489 - val_accuracy: 0.7346\n",
            "Epoch 12/75\n",
            "60/60 [==============================] - 18s 300ms/step - loss: 0.5824 - accuracy: 0.6995 - val_loss: 0.5425 - val_accuracy: 0.7204\n",
            "Epoch 13/75\n",
            "60/60 [==============================] - 18s 298ms/step - loss: 0.5868 - accuracy: 0.6807 - val_loss: 0.5470 - val_accuracy: 0.7251\n",
            "Epoch 14/75\n",
            "60/60 [==============================] - 18s 298ms/step - loss: 0.5613 - accuracy: 0.7053 - val_loss: 0.5441 - val_accuracy: 0.7062\n",
            "Epoch 15/75\n",
            "60/60 [==============================] - 18s 298ms/step - loss: 0.5677 - accuracy: 0.6974 - val_loss: 0.5620 - val_accuracy: 0.6777\n",
            "Epoch 16/75\n",
            "60/60 [==============================] - 18s 298ms/step - loss: 0.5666 - accuracy: 0.6927 - val_loss: 0.5468 - val_accuracy: 0.6872\n",
            "Epoch 17/75\n",
            "60/60 [==============================] - 18s 298ms/step - loss: 0.5668 - accuracy: 0.7037 - val_loss: 0.5247 - val_accuracy: 0.7393\n",
            "Epoch 18/75\n",
            "60/60 [==============================] - 18s 298ms/step - loss: 0.5589 - accuracy: 0.6990 - val_loss: 0.5224 - val_accuracy: 0.7251\n",
            "Epoch 19/75\n",
            "60/60 [==============================] - 18s 297ms/step - loss: 0.5552 - accuracy: 0.7011 - val_loss: 0.5387 - val_accuracy: 0.7299\n",
            "Epoch 20/75\n",
            "60/60 [==============================] - 18s 297ms/step - loss: 0.5539 - accuracy: 0.7090 - val_loss: 0.5221 - val_accuracy: 0.7630\n",
            "Epoch 21/75\n",
            "60/60 [==============================] - 18s 297ms/step - loss: 0.5515 - accuracy: 0.7074 - val_loss: 0.5259 - val_accuracy: 0.7251\n",
            "Epoch 22/75\n",
            "60/60 [==============================] - 18s 297ms/step - loss: 0.5506 - accuracy: 0.7027 - val_loss: 0.5268 - val_accuracy: 0.7441\n",
            "Epoch 23/75\n",
            "60/60 [==============================] - 18s 296ms/step - loss: 0.5508 - accuracy: 0.7079 - val_loss: 0.5284 - val_accuracy: 0.7441\n",
            "Epoch 24/75\n",
            "60/60 [==============================] - 18s 296ms/step - loss: 0.5459 - accuracy: 0.7042 - val_loss: 0.5069 - val_accuracy: 0.7678\n",
            "Epoch 25/75\n",
            "60/60 [==============================] - 18s 297ms/step - loss: 0.5440 - accuracy: 0.7226 - val_loss: 0.5213 - val_accuracy: 0.7204\n",
            "Epoch 26/75\n",
            "60/60 [==============================] - 18s 297ms/step - loss: 0.5335 - accuracy: 0.7310 - val_loss: 0.5441 - val_accuracy: 0.6777\n",
            "Epoch 27/75\n",
            "60/60 [==============================] - 18s 296ms/step - loss: 0.5479 - accuracy: 0.7058 - val_loss: 0.5274 - val_accuracy: 0.7346\n",
            "Epoch 28/75\n",
            "60/60 [==============================] - 18s 296ms/step - loss: 0.5321 - accuracy: 0.7289 - val_loss: 0.5004 - val_accuracy: 0.7536\n",
            "Epoch 29/75\n",
            "60/60 [==============================] - 18s 293ms/step - loss: 0.5282 - accuracy: 0.7263 - val_loss: 0.5132 - val_accuracy: 0.7299\n",
            "Epoch 30/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.5315 - accuracy: 0.7147 - val_loss: 0.5032 - val_accuracy: 0.7299\n",
            "Epoch 31/75\n",
            "60/60 [==============================] - 18s 293ms/step - loss: 0.5249 - accuracy: 0.7174 - val_loss: 0.5127 - val_accuracy: 0.7583\n",
            "Epoch 32/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.5199 - accuracy: 0.7273 - val_loss: 0.4980 - val_accuracy: 0.7346\n",
            "Epoch 33/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.5131 - accuracy: 0.7331 - val_loss: 0.4898 - val_accuracy: 0.7583\n",
            "Epoch 34/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.5072 - accuracy: 0.7389 - val_loss: 0.4854 - val_accuracy: 0.7488\n",
            "Epoch 35/75\n",
            "60/60 [==============================] - 18s 292ms/step - loss: 0.5253 - accuracy: 0.7210 - val_loss: 0.5190 - val_accuracy: 0.7204\n",
            "Epoch 36/75\n",
            "60/60 [==============================] - 18s 292ms/step - loss: 0.5098 - accuracy: 0.7373 - val_loss: 0.4867 - val_accuracy: 0.7820\n",
            "Epoch 37/75\n",
            "60/60 [==============================] - 18s 293ms/step - loss: 0.5119 - accuracy: 0.7315 - val_loss: 0.4463 - val_accuracy: 0.7915\n",
            "Epoch 38/75\n",
            "60/60 [==============================] - 18s 293ms/step - loss: 0.4963 - accuracy: 0.7541 - val_loss: 0.4651 - val_accuracy: 0.7488\n",
            "Epoch 39/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.5030 - accuracy: 0.7357 - val_loss: 0.4803 - val_accuracy: 0.7488\n",
            "Epoch 40/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.5072 - accuracy: 0.7415 - val_loss: 0.4910 - val_accuracy: 0.7773\n",
            "Epoch 41/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.5076 - accuracy: 0.7410 - val_loss: 0.4720 - val_accuracy: 0.8009\n",
            "Epoch 42/75\n",
            "60/60 [==============================] - 17s 287ms/step - loss: 0.5036 - accuracy: 0.7404 - val_loss: 0.4653 - val_accuracy: 0.7773\n",
            "Epoch 43/75\n",
            "60/60 [==============================] - 17s 287ms/step - loss: 0.4915 - accuracy: 0.7383 - val_loss: 0.4924 - val_accuracy: 0.7583\n",
            "Epoch 44/75\n",
            "60/60 [==============================] - 17s 287ms/step - loss: 0.4842 - accuracy: 0.7546 - val_loss: 0.4876 - val_accuracy: 0.7725\n",
            "Epoch 45/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.5009 - accuracy: 0.7410 - val_loss: 0.4740 - val_accuracy: 0.7488\n",
            "Epoch 46/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.4908 - accuracy: 0.7462 - val_loss: 0.4859 - val_accuracy: 0.7583\n",
            "Epoch 47/75\n",
            "60/60 [==============================] - 17s 286ms/step - loss: 0.4829 - accuracy: 0.7583 - val_loss: 0.4750 - val_accuracy: 0.7725\n",
            "Epoch 48/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.4841 - accuracy: 0.7583 - val_loss: 0.4654 - val_accuracy: 0.7536\n",
            "Epoch 49/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4837 - accuracy: 0.7478 - val_loss: 0.4842 - val_accuracy: 0.7773\n",
            "Epoch 50/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.4739 - accuracy: 0.7672 - val_loss: 0.4852 - val_accuracy: 0.7725\n",
            "Epoch 51/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.4766 - accuracy: 0.7572 - val_loss: 0.4655 - val_accuracy: 0.7867\n",
            "Epoch 52/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.4834 - accuracy: 0.7509 - val_loss: 0.4353 - val_accuracy: 0.8152\n",
            "Epoch 53/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.4788 - accuracy: 0.7551 - val_loss: 0.4761 - val_accuracy: 0.7867\n",
            "Epoch 54/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.4814 - accuracy: 0.7572 - val_loss: 0.4660 - val_accuracy: 0.7962\n",
            "Epoch 55/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.4684 - accuracy: 0.7745 - val_loss: 0.4452 - val_accuracy: 0.7915\n",
            "Epoch 56/75\n",
            "60/60 [==============================] - 17s 291ms/step - loss: 0.4663 - accuracy: 0.7735 - val_loss: 0.4733 - val_accuracy: 0.7820\n",
            "Epoch 57/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.4693 - accuracy: 0.7693 - val_loss: 0.4525 - val_accuracy: 0.7820\n",
            "Epoch 58/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.4702 - accuracy: 0.7719 - val_loss: 0.4806 - val_accuracy: 0.7962\n",
            "Epoch 59/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4518 - accuracy: 0.7792 - val_loss: 0.4776 - val_accuracy: 0.7536\n",
            "Epoch 60/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4565 - accuracy: 0.7808 - val_loss: 0.4814 - val_accuracy: 0.7630\n",
            "Epoch 61/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.4495 - accuracy: 0.7782 - val_loss: 0.4542 - val_accuracy: 0.7820\n",
            "Epoch 62/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.4456 - accuracy: 0.7850 - val_loss: 0.4495 - val_accuracy: 0.8057\n",
            "Epoch 63/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.4547 - accuracy: 0.7792 - val_loss: 0.4775 - val_accuracy: 0.7773\n",
            "Epoch 64/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.4510 - accuracy: 0.7792 - val_loss: 0.4526 - val_accuracy: 0.7867\n",
            "Epoch 65/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4414 - accuracy: 0.7887 - val_loss: 0.4480 - val_accuracy: 0.7678\n",
            "Epoch 66/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4442 - accuracy: 0.7960 - val_loss: 0.4459 - val_accuracy: 0.7962\n",
            "Epoch 67/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4366 - accuracy: 0.8018 - val_loss: 0.4581 - val_accuracy: 0.8057\n",
            "Epoch 68/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.4429 - accuracy: 0.7944 - val_loss: 0.4492 - val_accuracy: 0.7915\n",
            "Epoch 69/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.4477 - accuracy: 0.7840 - val_loss: 0.4502 - val_accuracy: 0.7915\n",
            "Epoch 70/75\n",
            "60/60 [==============================] - 17s 288ms/step - loss: 0.4319 - accuracy: 0.7944 - val_loss: 0.4354 - val_accuracy: 0.7820\n",
            "Epoch 71/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4376 - accuracy: 0.8002 - val_loss: 0.4495 - val_accuracy: 0.7583\n",
            "Epoch 72/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4434 - accuracy: 0.7871 - val_loss: 0.4286 - val_accuracy: 0.8104\n",
            "Epoch 73/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.4452 - accuracy: 0.7861 - val_loss: 0.4526 - val_accuracy: 0.7867\n",
            "Epoch 74/75\n",
            "60/60 [==============================] - 17s 289ms/step - loss: 0.4323 - accuracy: 0.7939 - val_loss: 0.4783 - val_accuracy: 0.7773\n",
            "Epoch 75/75\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.4449 - accuracy: 0.7819 - val_loss: 0.4769 - val_accuracy: 0.7630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw_xBTZUU4Cr",
        "outputId": "e9d24697-6a41-45d4-df71-a75028cc6ea0"
      },
      "source": [
        "loss, acc   = bcnn.model.evaluate(X_test, y_test, verbose=False);\n",
        "predictions = bcnn.model.predict(X_test)\n",
        "print(\"Test done!\")\n",
        "print(\"Mean accuracy:\\t {}\\nLoss:\\t\\t {}\".format(acc, loss))\n",
        "\n",
        "predictions"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test done!\n",
            "Mean accuracy:\t 0.1819196492433548\n",
            "Loss:\t\t 1.2205983400344849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7665872 , 0.23341279],\n",
              "       [0.6576779 , 0.34232214],\n",
              "       [0.8061638 , 0.19383624],\n",
              "       ...,\n",
              "       [0.6987473 , 0.30125272],\n",
              "       [0.7235032 , 0.27649683],\n",
              "       [0.73764235, 0.26235768]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp3mdUpkFWPz"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKtyod7dDrpv"
      },
      "source": [
        "import numpy      as np\n",
        "import pandas     as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow              import keras, feature_column\n",
        "from keras                   import utils\n",
        "from keras.layers            import Input, Conv1D, Conv2D, Dropout, MaxPooling1D, MaxPooling2D, Dense, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics         import accuracy_score\n",
        "\n",
        "TEST_SET     = \"test_set_1.csv\"\n",
        "TRAINING_SET = \"training_set.csv\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkiA9wRuEjPQ"
      },
      "source": [
        "class CNN:\n",
        "    \n",
        "    def __init__(self,\n",
        "                 n_epochs, \n",
        "                 batch_size, \n",
        "                 learning_rate,\n",
        "                 input_shape,\n",
        "                 n_classes,\n",
        "                 model,\n",
        "                 lr_reduction_epoch=60,\n",
        "                 mc_dropout_rate=0.6\n",
        "                 ):\n",
        "\n",
        "        self.n_epochs           = n_epochs\n",
        "        self.batch_size         = batch_size\n",
        "        self.learning_rate      = learning_rate\n",
        "        self.input_shape        = input_shape\n",
        "        self.n_classes          = n_classes\n",
        "        self.rate               = mc_dropout_rate\n",
        "        self.lr_reduction_epoch = lr_reduction_epoch\n",
        "\n",
        "        if   model == \"Basic\":\n",
        "          self.model            = self.BaseModel()\n",
        "        elif model == \"Bayesian\":\n",
        "          self.model            = self.BayesianModel()\n",
        "        else:\n",
        "          print(\"!!! Model not recognized !!!\")\n",
        "\n",
        "        print(\"Loaded \" + model + \" model.\")\n",
        "        \n",
        "        return \n",
        "\n",
        "    def BaseModel(self):\n",
        "\n",
        "      model = keras.models.Sequential()\n",
        "      model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=self.input_shape))\n",
        "      model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "      model.add(Dropout(0.5))\n",
        "      model.add(MaxPooling1D(pool_size=2))\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(100, activation='relu'))\n",
        "      model.add(Dense(self.n_classes, activation='softmax'))\n",
        "\n",
        "      return model\n",
        "      \n",
        "    def BayesianModel(self):\n",
        "      \n",
        "      inputs = Input(shape=self.input_shape)\n",
        "\n",
        "      # Block 1\n",
        "      x = Conv1D(64, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block1_conv1\")(inputs)\n",
        "      x = Dropout(rate=self.rate)(x, training = True) \n",
        "      x = Conv1D(64, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block1_conv2\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True) \n",
        "      x = MaxPooling1D(2, strides=2, name = \"block1_pool\")(x)\n",
        "\n",
        "      # Block 2\n",
        "      x = Conv1D(128, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block2_conv1\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True) \n",
        "      x = Conv1D(128, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block2_conv2\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True) \n",
        "      x = MaxPooling1D(2, strides=2, name = \"block2_pool\")(x)\n",
        "\n",
        "      # Block 3\n",
        "      x = Conv1D(256, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block3_conv1\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True) \n",
        "      x = Conv1D(256, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block3_conv2\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True)\n",
        "      x = Conv1D(256, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block3_conv3\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True)  \n",
        "      x = MaxPooling1D(2, strides=2, name = \"block3_pool\")(x)\n",
        "\n",
        "      # Block 4\n",
        "      x = Conv1D(512, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block4_conv1\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True) \n",
        "      x = Conv1D(512, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block4_conv2\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True)\n",
        "      x = Conv1D(512, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block4_conv3\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True)  \n",
        "      x = MaxPooling1D(2, strides=2, name = \"block4_pool\")(x)\n",
        "\n",
        "      # Block 5\n",
        "      x = Conv1D(512, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block5_conv1\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True) \n",
        "      x = Conv1D(512, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block5_conv2\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True)\n",
        "      x = Conv1D(512, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"block5_conv3\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True)  \n",
        "      x = MaxPooling1D(2, strides=2, name = \"block5_pool\")(x)\n",
        "\n",
        "      # Classifier\n",
        "      x = Flatten(name = \"flatten\")(x)\n",
        "      x = Dense(4096, activation = \"relu\", name = \"fc1\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True)\n",
        "      x = Dense(4096, activation = \"relu\", name = \"fc2\")(x)\n",
        "      x = Dropout(rate=self.rate)(x, training = True)\n",
        "      x = Dense(self.n_classes, activation = \"softmax\", name = \"predictions\")(x)\n",
        "\n",
        "      model = tf.keras.Model(inputs = inputs, outputs = x)\n",
        "\n",
        "      return model\n",
        "            \n",
        "    def train_model(self, x_train, y_train):\n",
        "        \n",
        "        x_train, y_train, x_val, y_val = self._split_validation_data(x_train, y_train, 0.1)\n",
        "\n",
        "        optimizer = tf.keras.optimizers.Adam(lr=self.learning_rate)\n",
        "        \n",
        "        self.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        history = tf.keras.callbacks.History()\n",
        "        scheduler_callback = tf.keras.callbacks.LearningRateScheduler(self.lr_scheduler, verbose=0)                                  \n",
        "\n",
        "        self.model.fit(x=x_train, \n",
        "                       y=y_train, \n",
        "                       epochs=self.n_epochs,\n",
        "                       batch_size=self.batch_size,\n",
        "                       validation_data=(x_val, y_val),\n",
        "                       callbacks=[\n",
        "                          history,\n",
        "                          scheduler_callback\n",
        "                        ])   \n",
        "        \n",
        "    @staticmethod\n",
        "    def _split_validation_data(x, y, validation_split):\n",
        "        rand_indexes = np.random.permutation(x.shape[0])\n",
        "\n",
        "        x = x[rand_indexes]\n",
        "        y = y[rand_indexes]\n",
        "        \n",
        "        x_validation = x[:int(len(x) * validation_split)]\n",
        "        y_validation = y[:int(len(x) * validation_split)]\n",
        "\n",
        "        x_train = x[int(len(x) * validation_split):]\n",
        "        y_train = y[int(len(x) * validation_split):]\n",
        "\n",
        "        return x_train, y_train, x_validation, y_validation\n",
        "\n",
        "    def lr_scheduler(self, epoch, lr):\n",
        "        if epoch == self.lr_reduction_epoch:\n",
        "            return lr * 0.1\n",
        "        else:\n",
        "            return lr "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCft4S9Evr-_"
      },
      "source": [
        "def compute_one_hot_encoding_map(train_df):\n",
        "\n",
        "  unique_aminoacids = set(list(''.join(train_df.Proteins.values))) # Set of aminoacids contained in the dataset\n",
        "  unique_aminoacids.add(\"Filling\")                                 # Additional fake aminoacid - used for filling the matrix, since every matrix should have the same dimension\n",
        "  unique_aminoacids.add(\"Stop\")                                    # Additional fake aminoacid - used as a stop row of the matrix\n",
        "\n",
        "  aminoacids_number = len(unique_aminoacids)                       # Number of distinct aminoacids\n",
        "\n",
        "  aminoacids_map = dict()                                          # Map initialization <aminoacid, one_hot_encoding>\n",
        "  index          = 0\n",
        "  zeros_list     = [0] * aminoacids_number                         # Reference zeros array. Iteratively filled with a 1 in the index-th index.\n",
        "\n",
        "  for aminoacid in unique_aminoacids:\n",
        "\n",
        "    encoding        = zeros_list.copy()                            # [0, 0, 0, 0, ..., 0]\n",
        "    encoding[index] = 1                                            # [1, 0, 0, 0, ..., ...] (example)\n",
        "\n",
        "    aminoacids_map[aminoacid] = encoding \n",
        "\n",
        "    index += 1\n",
        "\n",
        "  return aminoacids_map                                            # <aminoacid, one_hot_encoding>\n",
        "\n",
        "def one_hot_encode(aminoacids_map, protein, MAX_LEN = 5000):\n",
        "  protein = list(protein)                                          # [\"PROTEIN\"] => [\"P\", \"R\", \"O\", \"T\", \"E\", \"I\", \"N\"]\n",
        "\n",
        "  encoding = []                                                    # Matrix initialization\n",
        "\n",
        "  for aminoacid in protein:\n",
        "    encoding.append(aminoacids_map[aminoacid])                     # Mapping first N = len(protein) rows with the actual one hot encoding of the aminoacids\n",
        "\n",
        "  for index in range(len(encoding), MAX_LEN - 1):                  # Filling additional MAX_LEN - N - 1 rows with a padding\n",
        "    encoding.append(aminoacids_map[\"Filling\"])\n",
        "\n",
        "  encoding.append(aminoacids_map[\"Stop\"])                          # Filling the last row with the stop encoding\n",
        "\n",
        "  return np.array(encoding, dtype = np.float64) \n",
        "\n",
        "def clean_dataset(df):\n",
        "  mask = df.Proteins.str.contains(\",\") == True\n",
        "\n",
        "  new_rows = []\n",
        "\n",
        "  for index, row in df[mask].iterrows():\n",
        "    sequences = row.Proteins.split(\",\")\n",
        "    \n",
        "    for sequence in sequences:\n",
        "      row.Proteins = sequence\n",
        "      new_rows.append(row)\n",
        "\n",
        "  df.drop(df[mask].index, inplace = True)\n",
        "  return df.append(pd.DataFrame(new_rows, columns=df.columns)).reset_index()"
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}